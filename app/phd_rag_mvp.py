# -*- coding: utf-8 -*-
"""PHD_RAG_MVP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mGiC8AJvPrS-RIVQys7khHQPMv1R21CQ
"""

!pip install sentence-transformers faiss-cpu pymupdf

import fitz  # PyMuPDF
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

def is_valid_text(text):
    if len(text.strip()) < 100:
        return False
    blacklist = [
        "Downloaded via",
        "sharingguidelines",
        "Copyright",
        "All rights reserved"
    ]
    for b in blacklist:
        if b.lower() in text.lower():
            return False
    return True

def load_pdf(path):
    doc = fitz.open(path)
    pages = []
    for page in doc:
        text = page.get_text()
        if is_valid_text(text):
            pages.append(text)
    return pages

def chunk_pages(pages, chunk_size=400, overlap=80):
    chunks = []
    for page_id, text in enumerate(pages):
        sentences = text.split(". ")
        current = ""
        for sent in sentences:
            if len(current) + len(sent) < chunk_size:
                current += sent + ". "
            else:
                chunks.append({
                    "text": current.strip(),
                    "page": page_id
                })
                current = sent + ". "
        if current.strip():
            chunks.append({
                "text": current.strip(),
                "page": page_id
            })
    return chunks

def keep_claim_like_chunks(chunks):
    keywords = ["propose", "demonstrate", "show", "indicate", "outperform", "improve"]
    filtered = []
    for c in chunks:
        if any(k in c["text"].lower() for k in keywords):
            filtered.append(c)
    return filtered

chunks = chunk_pages(pages)
chunks = keep_claim_like_chunks(chunks)

model = SentenceTransformer("all-MiniLM-L6-v2")

def embed_chunks(chunks):
    texts = [c["text"] for c in chunks]
    embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)
    return embeddings

def build_faiss_index(embeddings):
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    return index

def retrieve(query, index, chunks, k=5):
    q_emb = model.encode([query], convert_to_numpy=True)
    _, idx = index.search(q_emb, k)
    results = []
    for i in idx[0]:
        results.append(chunks[i])
    return results

pages = load_pdf("/content/dmxp-a-de-novo-small-molecule-3d-structure-predictor-with-graph-attention-networks.pdf")
chunks = chunk_pages(pages)
embeddings = embed_chunks(chunks)
index = build_faiss_index(embeddings)

results = retrieve("drug toxicity prediction", index, chunks)

for r in results:
    print(f"[Page {r['page']}]")
    print(r["text"][:300])
    print("-" * 50)